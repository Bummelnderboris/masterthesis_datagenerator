{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der in Abbildung \\ref{...} gezeigte Generator wird in diesem Jupyter Notebook umgesetzt. Zunächst müssen alle relevanten Bibliotheken installiert und importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First the needed bibliotheks and imports have to be set up\n",
    "#!pip install numpy\n",
    "#!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell handles imports / set ups\n",
    "\n",
    "##LIBRARIES\n",
    "\n",
    "#\"Faker is a Python package that generates fake data for you. \" [from the Faker documentation]\n",
    "#import faker library\n",
    "from faker import Faker\n",
    "#create an instance of Faker\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Set the precision of decimals for the whole notebook on 2\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden einfach Funktionen sowie ein Set aus Wörtern, welche die einzigartigen Elemente abbilden generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL CONTAINS SOME SIMPLE FUNCTIONS WHICH WILL BE USED MORE OFTEN IN THE PROGRAMM\n",
    "\n",
    "#Declare a decision boundry function, to create a boundry value each time a decision is to be made**\n",
    "def decide():\n",
    "    decision_boundry = np.random.uniform(0,1,1)\n",
    "    return decision_boundry\n",
    "\n",
    "#Declare a function to let values vary along a uniform distribution around a given variation. This is a placeholder function for **\n",
    "def uniform_variance(value, variation):\n",
    "    low_boarder = value - value * variation\n",
    "    top_boarder = value + value * variation\n",
    "    \n",
    "    value = np.random.uniform(low_boarder,top_boarder,1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GENERATE BAG OF UNIQUE ELEMENTS\n",
    "##Also gnerate a bag for frequently used words for sentence generation in the abstracts\n",
    "##Set the size of the bag of unique Elements\n",
    "\n",
    "words_to_create = 150000\n",
    "\n",
    "\n",
    "#This function takes an integer and returns a list of unique words which is the size of the given integer minus deletet doublicates \n",
    "def create_bag_of_unique_words(word_amount_to_create):\n",
    "\n",
    "    words = []\n",
    "\n",
    "    words_created=0\n",
    "    \n",
    "    while words_created < word_amount_to_create:\n",
    "        words.append(fake.word())\n",
    "        words_created = words_created + 1 \n",
    "\n",
    "    \n",
    "    #check for duplikates\n",
    "    unique_words = []\n",
    "    double = 0\n",
    "    for x in words:\n",
    "        if x not in unique_words:\n",
    "            unique_words.append(x)\n",
    "        else:\n",
    "            double=+1\n",
    "    \n",
    "    return unique_words\n",
    "            \n",
    "            \n",
    "#CREATE A FUNCTION FOR FREQUENTLY USED WORDS (FOR SENTENCE GENERATION)\n",
    "def create_bag_of_frequently_used_words(bagsize):\n",
    "    #Create a list of frequently used words\n",
    "    frequently_used_words=[]\n",
    "    frequently_used_words.append(unique_words[:bagsize])\n",
    "    del unique_words[:bagsize]\n",
    "    \n",
    "    return frequently_used_words\n",
    "\n",
    "unique_words = create_bag_of_unique_words(words_to_create)\n",
    "frequently_used_words = create_bag_of_frequently_used_words(20)\n",
    "\n",
    "## Comment:\n",
    "#Combination of frequently used words and 'normal' words to create sentences with topic words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird die initiale erste Generation an Topics als eine Liste aus leeren Listen erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], []]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###INITIALIZE EMPTY TOPICS\n",
    "\n",
    "##Create bag of x topics\n",
    "topic_amount = 5\n",
    "\n",
    "#This function takes an amount of topics as integer and returns a list of empty lists according to the amount\n",
    "def initialize_empty_topics(amounts_of_topics):\n",
    "    \n",
    "    topics_to_create = amounts_of_topics\n",
    "\n",
    "    ##Create empty list of initial topics\n",
    "    topic_list_empty = []\n",
    "    topics_created = 0\n",
    "    while topics_created < topics_to_create:\n",
    "        topic_list_empty.insert(0, [])\n",
    "        topics_created += 1\n",
    "    \n",
    "    return topic_list_empty\n",
    "\n",
    "\n",
    "topic_list_empty = initialize_empty_topics(topic_amount)\n",
    "\n",
    "topic_list_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden initiale Keywörter als Topic eigene Elemente diesen zugeordnet. Dabei ist es irrelevant, welche Bedeutung die Wörter haben, da über diesen Ansatz die kategoriale Bedeutung der Wörter diesen neu zugeorndet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['next', 'decide', 'among', 'whether', 'by']\n",
      "['our']\n",
      "['left', 'community', 'radio', 'more', 'site']\n",
      "['agency', 'wear', 'thing', 'scene']\n",
      "['attorney', 'actually', 'college']\n"
     ]
    }
   ],
   "source": [
    "###INITIALIZE KEYWORDS FOR EACH TOPIC\n",
    "\n",
    "#State the low and top boarder for key words per topic\n",
    "min_words_per_topic = 1 \n",
    "max_words_per_topic = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define a function which will insert the initial keywords for every topic\n",
    "def initialize_keywords_to_topic(empty_topic_list):\n",
    "    for topic in empty_topic_list:\n",
    "        keyword_amount = rnd.randint(min_words_per_topic, max_words_per_topic)\n",
    "        keywords_inserted = 0\n",
    "        while keywords_inserted < keyword_amount:\n",
    "            #Append a unique word to the topic as a keyword of this topic\n",
    "            topic.insert(0,unique_words[keywords_inserted])\n",
    "            #Delete the word out of the baggs of words to ensure, this entry won't be taken a second time\n",
    "            del unique_words[keywords_inserted]\n",
    "            keywords_inserted = keywords_inserted +1\n",
    "    return (empty_topic_list)\n",
    "\n",
    "topic_list = initialize_keywords_to_topic(topic_list_empty)\n",
    "# Print the keywords of each topic.\n",
    "for topic in topic_list:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun da die Topic mit deren beschreibenden Elementen gesetzt sind, können die Verhaltensparameter der Topics initialisiert werden. Die aus der Wahrscheinlichkeit selber, einer Liste möglicher Counter und einer Liste der Verhaltensentscheidungen besteht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###INITIALIZE BEHAVIOURAL PROBABILITIES FOR EACH TOPIC\n",
    "\n",
    "##This function takes an empty topic list and generate for each topic probabilities, different behaviours will occeu\n",
    "##Note: The behaviours are implemented as fucntions which are called depending on a random decisionboundry for each \n",
    "##generation step and the in this function (initialize_topic_behaviour_parameters) stated probabilities. This \n",
    "##implementation aims to mimic tendencies for behaviours.\n",
    "def initialize_topic_behaviour_parameters(empty_topic_list):\n",
    "\n",
    "    for topic in empty_topic_list:\n",
    "        \n",
    "        \n",
    "        #Initialize the behavioural parameters**\n",
    "        topic_probability_is_elaborated = [float(np.random.uniform(0,1,1)), [0], []]\n",
    "        \n",
    "        topic_probability_creates_new_word = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        topic_probability_uses_different_topic = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        topic_probability_is_used = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        \n",
    "        #Setting the behavioural parameters here just with implemented with standard uniform distributions in a certain range\n",
    "        #between 0 and 1. Refining these functions in future work could include changing behavioural probabilities depending \n",
    "        #on topic size and topic contents.\n",
    "        \n",
    "        \n",
    "        behavioural_paramters = [topic_probability_is_elaborated, topic_probability_uses_different_topic,\n",
    "                                 topic_probability_is_used,topic_probability_creates_new_word]\n",
    "        #,topic_probability_creates_new_word, topic_probability_uses_different_topic\n",
    "        \n",
    "\n",
    "        ##FUTURE WORK: Disruptive Technologien implementieren: Ein Topic einstampfen, wenn ein anderes Steigt.\n",
    "        ##FUTRE WORK: Ressourcen pro Generation implementieren, so wie es wörter für topic gibt, kann es\n",
    "        ##Topics für neue Generation geben. --> Es wird festgelegt wie viele Topics pro Generation generiert werden\n",
    "        ##können / sollen und dann wird die Anzahl gemäß den Wahrscheinlichkeiten als Anteil zugewiesen.\n",
    "\n",
    "        topic.append(behavioural_paramters)\n",
    "        \n",
    "\n",
    "        #IMPORTNANT NOTE:\n",
    "        #BEHAVIOUR 1 = IF TOPIC IS ELABORATED\n",
    "        #BEHAVIOUR 2 = TOPIC CREATES NEW WORD\n",
    "        #BEHAVIOUR 3 = TOPIC USES DIFFERENT TOPIC\n",
    "        #BEHAVIOUR 4 = TOPIC IS USED IN DIFFERENT TOPIC\n",
    "initialize_topic_behaviour_parameters(topic_list_empty)\n",
    "topic_list = topic_list_empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun da sie erste Generation an Topics initialisiert ist, werden die jeweiligen Sets an Funktionen: Triggerfunktionen, Zählfunktionen, Verhaltenveränderungsfunktionen und Verhaltensfunktionen umgesetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Verhaltensfunktionen bietet es sich an, die Namensnemmung der Verhaltensauftretenswahrscheinlichkeiten zu übernehmen: topic_probability_is_elaborated, topic_probability_creates_new_word, topic_probability_uses_different_topic, topic_probability_is_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENSFUNKTIONEN\n",
    "\n",
    "#merge_topic_with_unique_word takes a word (from a topic) and merges it with a random word from unique_words.\n",
    "def merge_topicword_with_uniqueword(word):\n",
    "    word_position = rnd.randint(0,len(unique_words))\n",
    "    new_word = str(word) + str(unique_words[word_position])\n",
    "    \n",
    "    #if the word becomes to long keep the last 12 digits\n",
    "    if len(new_word)>18:\n",
    "        new_word = new_word[-12:]\n",
    "    return new_word\n",
    "\n",
    "\n",
    "##The following two functions have to be linked to each other, so if one is called it will set the boolean entry\n",
    "##in the behaviour tracking list of the other behaviour.\n",
    "###UNFINISHED!\n",
    "#This function alway returns a random word of a random different topic\n",
    "def use_different_topic(random_topic_number):\n",
    "    # This implementation enables the error of elaborating on the own topic when choosing a random other topic.\n",
    "    if random_topic_number < 0:\n",
    "        random_topic_number = 0\n",
    "    elif random_topic_number > len(topic_list):\n",
    "        random_topic_number = len(topic_list)\n",
    "    \n",
    "    t_word = topic_list[random_topic_number-1][rnd.randint(0,len(topic)-2)]\n",
    "    return t_word\n",
    "\n",
    "\n",
    "#This function writes a document for another topic with its own word as vairable.\n",
    "def is_used_in_a_different_topic(current_topic_list):\n",
    "    \n",
    "    # This implementation enables the error of elaborating on the own topic when choosing a random other topic.\n",
    "    r = rnd.randint(0,len(topic_list)-1)\n",
    "    rt = rnd.randint(0,len(topic_list[r])-1)\n",
    "    \n",
    "    topic_to_write_in = topic_list[r]\n",
    "    words_to_write_in_other_topic = current_topic_list[0]\n",
    "    \n",
    "    t_subtopic = []\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Zählfunktionen verwenden die Liste der Booleaneinträge einer Verhaltenswahrscheinlichkeit eines Topic und betrachten auf Basis dieser, ob der Counter der Verhaltenswahrscheinlichkeit geändert wird. Für diesen Prototypen schreiben wir zunächst zwei einfache Zählfunktionen, eine welche den Counter stets um eins erhöht, falls ein Verhalten getriggert wurde und auf null setzt, falls dem nicht so ist. Die zweite Funktion betrachtet, ob ein Verhalten vier mal oder öfter in den letzten fünf Generationen aufgetreten ist. Für eine bessere Übersichtlichkeit des Codes kann es hilfreich sein, alle Zählfunktionen so zu bedenken, dass diese nach oder am Ende eines Verhaltens implementiert werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ZÄHLFUNKTIONEN\n",
    "\n",
    "def simple_count_function_1(topic):\n",
    "    if boolean == True:\n",
    "        print(\"wait\")\n",
    "        \n",
    "    \n",
    "#def simple_count_function_2(booleanliste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENVERÄNDERUNGSFUNKTIONEN\n",
    "\n",
    "def simple_behaviour_change(topic):\n",
    "    for behaviour in topic[-1]:\n",
    "        \n",
    "        #print(type(behaviour[0]))\n",
    "        behaviour[0] = uniform_variance(behaviour[0],0.2)\n",
    "\n",
    "        if behaviour[0] > 1:\n",
    "            behaviour[0] = 0.98\n",
    "                \n",
    "        \n",
    "        #behaviour[2].append(0)\n",
    "        print(behaviour[2])\n",
    "        #this part inserts a 0 for every behaviour in the behaviour appearence list of a topic, list entry will be\n",
    "        #changed to a one if a behaviour is triggered\n",
    "        \n",
    "    return topic[-1]\n",
    "\n",
    "\n",
    "\n",
    "def behaviour_change_based_on_information(topic):\n",
    "    if topic[-1][2[0]] > 0.9:\n",
    "        print(\"Special\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun da die Funktionen und die Initialtopics definiert sind, gilt es die Logik der Bildung einer Generation umzusetzen. Eine Generation wird erstellt, indem zu jedem Topic ein Subtopic Informationsraum ausgearbeitet wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CREATE A SUBTOPIC SPACE FOR TOPIC\n",
    "\n",
    "\n",
    "\n",
    "#This function takes a topic and elaborates it into a subtopic and returns the subtopic\n",
    "def elaborate_topic(topic, subtopic_space):\n",
    "    \n",
    "\n",
    "    \n",
    "    #Set the amounts of words used in that subtopic**\n",
    "    subtopic_word_amount = rnd.randint(4,6)\n",
    "    subtopic_words_picked = 0\n",
    "    \n",
    "\n",
    "\n",
    "    while subtopic_words_picked < subtopic_word_amount:\n",
    "        decisionboundry = decide()\n",
    "\n",
    "        #Always use a random word from the topic space for the subtopic\n",
    "        position_word_elaborated = rnd.randint(0,len(topic)-1)\n",
    "        subtopic_space.insert(0,topic[position_word_elaborated])\n",
    "\n",
    "\n",
    "        subtopic_words_picked += 1\n",
    "\n",
    "\n",
    "        ##Now check for the behavioural functions: How will the topic be elaborated\n",
    "\n",
    "\n",
    "        #Maybe create a new word\n",
    "        if topic[-1][1][0] > decisionboundry: #topic[-1][1][0] = probability for creating a new word\n",
    "            new_word = merge_topicword_with_uniqueword(topic[rnd.randint(0,len(topic)-1)])\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            subtopic_words_picked += 1\n",
    "\n",
    "            #Set the behaviour_was_used variable to 1, if this if loop is reached once within a topic.\n",
    "            #topic[-1][1][2][0] is the first variable of the behaviour tracking list, which is initialized as a zero\n",
    "            topic[-1][1][-1] = 1\n",
    "            #topic[-1][1][2].insert(0,1)\n",
    "\n",
    "        \n",
    "        #Maybe use a different topic\n",
    "        if topic[-1][2][0] > decisionboundry: #topic[-1][2][0] = probability for creating a new word\n",
    "                \n",
    "            t_random_1 = rnd.randint(0,len(topic_list)-1)\n",
    "            new_word = use_different_topic(t_random_1)\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            \n",
    "            #Set the behaviour_was_used variable of the topic which is used to 1, if this if loop is reached once within a topic.\n",
    "            topic_list[t_random_1][-1][3][-1] = 1\n",
    "            #topic_list[t_random_1][-1][3][-1].insert(0,1)\n",
    "            \n",
    "            #Set the uses_a_different_topic variable of this topic to 1.\n",
    "            topic[-1][2][-1] = 1\n",
    "            #topic[-1][1][2].insert(0,1)\n",
    "\n",
    "            subtopic_words_picked += 1\n",
    "            \n",
    "            \n",
    "        #Maybe be used in a different topic\n",
    "        if topic[-1][3][0] > decisionboundry: #topic[-1][1][0] = probability for creating a new word\n",
    "            continue\n",
    "            #this behaviour is not yet elaborated, beacuse, to stay logical consistent in the meening of behaviours, this would\n",
    "            #generate a whole new subtopic space for a different topic, which is not neccesary here, but implemented to examine\n",
    "            #the possbilities of cross topic behaviour settings.\n",
    "            \n",
    "        \n",
    "        #..more behaviours to append for future work\n",
    "        #Maybe use a topic from another topic space (parent generation) ...pending\n",
    "\n",
    "\n",
    "\n",
    "    #print(t_subtopic)\n",
    "    #print(topic)\n",
    "    return subtopic_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic[-1][1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkung: Für diesen Proptotypen hätte man die beiden Verhaltensweisen: wird genutzt von anderen topic und nutzt anderes topic zusammenfassen können zu einem Parameter der Topicübergreifenden Wortverwendung allgemein. Da jedoch die Untersuchung des Indexierens auf den Informationsraum anderer Topics zumindest in diesem Prototypen aufgegriffen werden soll, ist diese etwas umständlichere Version entstanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS CELL elaborates a given list of topics to a next generation of topic\n",
    "\n",
    "#Create the list, where each subtopic generation will be stored  \n",
    "topic_space_master = []\n",
    "\n",
    "subtopic = []\n",
    "#This function takes a list of topics, checks if the probability if a topic is elaborated and if yes, \n",
    "#calls elaborate_topic on the current topic, takes the result and stores it as a sub topic in the subtopic_space.\n",
    "#In the end the function appends the temporary subtopic_space to the global topic_space_master. (This implementation,\n",
    "#let have each generation stored in an own list of lists with the most current once in the beginning)\n",
    "def elaborate_topic_list(topic_list):\n",
    "\n",
    "    t_subtopic = []\n",
    "    #The simnple_behaviour_change function also sets a list of 0 for each generation for every topic behaviour as preset, which\n",
    "    #cna then be set to one if it is triggered. This is important here, so function like uses_different_topic can change the\n",
    "    #variable of a different topic without concerning about the variation of length of lists.\n",
    "    for topic in topic_list:\n",
    "        ##Vary the behaviour probabilities of each subtopic**\n",
    "        subtopic_parameters = simple_behaviour_change(topic)\n",
    "        t_subtopic.append(subtopic_parameters)\n",
    "    \n",
    "    \n",
    "    subtopic_space = []\n",
    "    \n",
    "    for topic in topic_list:\n",
    "        \n",
    "        topic_counter = 0\n",
    "        \n",
    "        #This loop elaborates a topic dpeending on its probability to be elaborated until the decision_boundry will be\n",
    "        #above the topic probability for being elaborated\n",
    "        while True: \n",
    "            \n",
    "            decision_boundry = decide()\n",
    "\n",
    "            t_subtopic = []\n",
    "            \n",
    "            #check \n",
    "            if topic[-1][0][0]> decision_boundry:\n",
    "                \n",
    "                #Call the elaborate_topic_function which returns a subtopic space for the topic including new elements and \n",
    "                t_subtopic = elaborate_topic(topic, t_subtopic)\n",
    "\n",
    "                #Append a one in the behaviour tracking list one:\n",
    "                topic[-1][0][-1].insert(0,1)\n",
    "                \n",
    "                \n",
    "                #Store the new generation\n",
    "                subtopic_space.append(t_subtopic)\n",
    "\n",
    "                topic_counter += 1\n",
    "                \n",
    "\n",
    "                if topic_counter > 10:\n",
    "                    break\n",
    "            else:\n",
    "                #Append a zero in the behaviour tracking list one:\n",
    "                topic[-1][0][-1].insert(0,0)\n",
    "                break\n",
    "    \n",
    "    #print(\"Returning subtopic\")\n",
    "    #print(subtopic_space)\n",
    "    #for t_subtopic in \n",
    "    #print(t_subtopic)\n",
    "    return subtopic_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "topic_space_master = elaborate_topic_list(topic_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['decidethan', 'next', 'decide', 'radio', 'byproduce', 'by'],\n",
       " ['decide', 'nexta', 'next', 'next', 'byleave', 'among'],\n",
       " ['nextway', 'by', 'agency', ' []]]quickly', 'decide'],\n",
       " ['actually', 'bydeep', 'by', 'whether', 'whether'],\n",
       " ['thing',\n",
       "  'byMr',\n",
       "  'by',\n",
       "  [[0.98, [0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [array([0.459]), [0], 1],\n",
       "   [array([0.355]), [0], 1],\n",
       "   [array([0.033]), [0], 1]]],\n",
       " [[[0.98, [0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [array([0.459]), [0], 1],\n",
       "   [array([0.355]), [0], 1],\n",
       "   [array([0.033]), [0], 1]],\n",
       "  'community',\n",
       "  'amonglittle',\n",
       "  [[0.98, [0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "   [array([0.459]), [0], 1],\n",
       "   [array([0.355]), [0], 1],\n",
       "   [array([0.033]), [0], 1]]],\n",
       " ['whetherimportant', 'among', 'by', 'by', 'decide'],\n",
       " ['decide', 'nextcreate', 'by', 'whether'],\n",
       " ['next', 'among', 'nextparticipant', 'by'],\n",
       " ['college', 'amongtable', 'by', 'decide', 'by'],\n",
       " ['next', 'agency', 'nextmagazine', 'decide'],\n",
       " ['wear',\n",
       "  '], 1]]minute',\n",
       "  'our',\n",
       "  [[array([0.295]), [0], [0, 1, 1]],\n",
       "   [array([0.118]), [0], 1],\n",
       "   [array([0.028]), [0], 1],\n",
       "   [array([0.308]), [0], 1]],\n",
       "  'our',\n",
       "  'our'],\n",
       " [[[array([0.295]), [0], [0, 1, 1]],\n",
       "   [array([0.118]), [0], 1],\n",
       "   [array([0.028]), [0], 1],\n",
       "   [array([0.308]), [0], 1]],\n",
       "  [[array([0.295]), [0], [0, 1, 1]],\n",
       "   [array([0.118]), [0], 1],\n",
       "   [array([0.028]), [0], 1],\n",
       "   [array([0.308]), [0], 1]],\n",
       "  'our',\n",
       "  'our'],\n",
       " ['more',\n",
       "  'left',\n",
       "  [[array([0.295]), [0], [0, 1, 1]],\n",
       "   [array([0.118]), [0], 1],\n",
       "   [array([0.028]), [0], 1],\n",
       "   [array([0.308]), [0], 1]],\n",
       "  'communityblue',\n",
       "  [[array([0.979]), [0], [0, 1, 1]],\n",
       "   [array([0.187]), [0], 1],\n",
       "   [array([0.084]), [0], 1],\n",
       "   [array([0.123]), [0], 1]]],\n",
       " ['attorney',\n",
       "  '], 1]]reduce',\n",
       "  [[array([0.979]), [0], [0, 1, 1]],\n",
       "   [array([0.187]), [0], 1],\n",
       "   [array([0.084]), [0], 1],\n",
       "   [array([0.123]), [0], 1]],\n",
       "  [[array([0.979]), [0], [0, 1, 1]],\n",
       "   [array([0.187]), [0], 1],\n",
       "   [array([0.084]), [0], 1],\n",
       "   [array([0.123]), [0], 1]]],\n",
       " ['wear',\n",
       "  [[array([0.455]), [0], [0, 1, 1]],\n",
       "   [array([0.28]), [0], 1],\n",
       "   [array([0.35]), [0], 1],\n",
       "   [array([0.473]), [0], 1]],\n",
       "  'wear',\n",
       "  'thingresult',\n",
       "  [[array([0.455]), [0], [0, 1, 1]],\n",
       "   [array([0.28]), [0], 1],\n",
       "   [array([0.35]), [0], 1],\n",
       "   [array([0.473]), [0], 1]],\n",
       "  [[array([0.455]), [0], [0, 1, 1]],\n",
       "   [array([0.28]), [0], 1],\n",
       "   [array([0.35]), [0], 1],\n",
       "   [array([0.473]), [0], 1]]],\n",
       " [[[array([0.455]), [0], [0, 1, 1]],\n",
       "   [array([0.28]), [0], 1],\n",
       "   [array([0.35]), [0], 1],\n",
       "   [array([0.473]), [0], 1]],\n",
       "  'agency',\n",
       "  'wear',\n",
       "  'thing',\n",
       "  'scene'],\n",
       " ['attorney', 'college', 'college', '0], 1]]young', 'attorney'],\n",
       " ['], 1]]animal',\n",
       "  'college',\n",
       "  'actually',\n",
       "  'attorneyattention',\n",
       "  [[array([0.813]), [0], [0, 1, 1]],\n",
       "   [array([0.385]), [0], 1],\n",
       "   [array([0.158]), [0], []],\n",
       "   [array([0.038]), [0], 1]],\n",
       "  'college']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_space_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CODE FOR VOLATILE BEHAVIOUR TO GENERATE STOCK DATA (CAN BE USED ON TEXT GENERATION FOR FUTURE WORK)\n",
    "#rnd = np.random.uniform(0,1); # generate number, 0 <= x < 1.0\n",
    "#volatility = 0.2\n",
    "#old_price = new_price\n",
    "#change_percent = 2 * volatility * rnd\n",
    "#if change_percent > volatility:\n",
    "#    change_percent -= (2 * volatility)\n",
    "#change_amount = old_price * change_percent\n",
    "#new_price = old_price + change_amount\n",
    "#print (old_price, new_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
